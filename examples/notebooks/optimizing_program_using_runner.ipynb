{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f0ebeec",
   "metadata": {},
   "source": [
    "## How to optimize an MLIR-AIR program using AIR-Runner performance model\n",
    "\n",
    "This notebook should give a step-by-step guide on how to generate performance time traces using MLIR-AIR's performance simulator, AIR-Runner, and how AIR-Runner could help a user with optimizing an MLIR-AIR program. In this demonstration, we use matrix multiplication as an example.\n",
    "\n",
    "### Outline\n",
    "- Compile a matrix multiplication program written in MLIR's LinAlg dialect (one single `linalg.matmul` op) using MLIR-AIR.\n",
    "- Use AIR-Runner to simulate the performance of the compiled program.\n",
    "- Based on the simulation time traces, iteratively apply MLIR-AIR compiler optimizations to improve the program's performance on AIEs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3738533",
   "metadata": {},
   "source": [
    "### Compile a matrix multiplication program written in MLIR's LinAlg dialect (one single `linalg.matmul` op) using MLIR-AIR\n",
    "\n",
    "Use MLIR's Python binding to create the input program: a single `linalg.matmul` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import air.compiler.util\n",
    "\n",
    "from air.mlir.dialects import func\n",
    "from air.mlir.dialects import linalg\n",
    "from air.mlir.ir import *\n",
    "import air.mlir.passmanager\n",
    "\n",
    "import sys\n",
    "\n",
    "def matmul_on_tensors(m, n, k, dtype):\n",
    "    module = Module.create()\n",
    "    with InsertionPoint(module.body):\n",
    "        @func.FuncOp.from_py_func(\n",
    "            RankedTensorType.get((m, k), dtype), RankedTensorType.get((k, n), dtype),\n",
    "            RankedTensorType.get((m, n), dtype))\n",
    "        def matmul(lhs, rhs, out):\n",
    "            linalg.matmul(lhs, rhs, outs=[out])\n",
    "    return module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b527841d",
   "metadata": {},
   "source": [
    "Compile the program using MLIR-AIR, with a stack of compilation passes described in `pipeline`. To print out the compiled MLIR-AIR program, please uncomment `print (air_module)` at the end of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joined-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "with air.mlir.ir.Context(), Location.unknown():\n",
    "\n",
    "    air_module = matmul_on_tensors(256, 256, 1536, BF16Type.get())\n",
    "    \n",
    "    # convert linalg on tensors to linalg on memrefs\n",
    "    pm = air.mlir.passmanager.PassManager.parse(air.compiler.util.LINALG_TENSOR_TO_MEMREF_PIPELINE)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # tile and map to air\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        # L1 and L2 tiling\n",
    "        \"air-linalg-codegen{l2-tile-size=64,64,128 l2-promote=true l1-tile-size=32,32,32 l1-promote=true}\",\n",
    "        # clean up\n",
    "        \"canonicalize\", \"cse\",\n",
    "        # bind depth 1 scf.parallel op as air.herd (i.e. AIE kernel)\n",
    "        \"air-par-to-herd{depth=1}\",\n",
    "        # bind data copy ops to AIE's DMA resources\n",
    "        \"air-copy-to-dma\",\n",
    "        # bind depth 0 scf.parallel op as air.launch\n",
    "        \"air-par-to-launch{has-air-segment=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # generate dependency information for runner\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        # analyze the data dependency between asynchronous events\n",
    "        \"air-dependency\",\n",
    "        # convert air.dma data movement ops into half-DMA 'air.channel' puts and gets\n",
    "        \"air-dma-to-channel\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        # clean up dependency graph\n",
    "        \"air-dependency-canonicalize\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        # place air.herd to physical locations in air.segment (Greedy algorithm)\n",
    "        \"air-place-herds{num-rows=2 num-cols=2 row-anchor=0 col-anchor=0}\"\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # print (\"\\nAIR Dialect Module (async)\\n\")\n",
    "    # print (air_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9fec97b",
   "metadata": {},
   "source": [
    "### Use AIR-Runner to simulate the performance of the compiled program.\n",
    "\n",
    "AIR-Runner analyzes the program's schedule, and based on a user-provided resource model of the target device, generates time traces to estimate the performance. The resource model is queried at run-time throughout the simulation, so that both static and dynamic resource allocations are monitored, and resource constraints are constantly enforced.\n",
    "\n",
    "Below is an example resource model which describes a hypothetical custom hardware, named \"testdevice\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tired-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = {\n",
    "    \"clock\": 1000000000,\n",
    "    \"cores\": 1,\n",
    "    \"datatypes\": [\n",
    "        {\n",
    "        \"bytes\": 1,\n",
    "        \"name\": \"i8\"\n",
    "        },\n",
    "        {\n",
    "        \"bytes\": 2,\n",
    "        \"name\": \"bf16\"\n",
    "        },\n",
    "        {\n",
    "        \"bytes\": 4,\n",
    "        \"name\": \"i32\"\n",
    "        }\n",
    "    ],\n",
    "    \"devicename\": \"testdevice\",\n",
    "    \"kernels\": {\n",
    "        \"linalg.copy\": {\n",
    "            \"datatypes\": {\n",
    "                \"i8\": {\n",
    "                    \"ops_per_core_per_cycle\": 32,\n",
    "                    \"efficiency\": 1\n",
    "                },\n",
    "                \"bf16\": {\n",
    "                    \"ops_per_core_per_cycle\": 32,\n",
    "                    \"efficiency\": 1\n",
    "                },\n",
    "                \"i32\": {\n",
    "                    \"ops_per_core_per_cycle\": 16,\n",
    "                    \"efficiency\": 1\n",
    "                }\n",
    "            },\n",
    "            \"name\": \"linalg.copy\"\n",
    "        },\n",
    "        \"linalg.fill\": {\n",
    "            \"datatypes\": {\n",
    "                \"i8\": {\n",
    "                    \"ops_per_core_per_cycle\": 32,\n",
    "                    \"efficiency\": 1\n",
    "                },\n",
    "                \"bf16\": {\n",
    "                    \"ops_per_core_per_cycle\": 32,\n",
    "                    \"efficiency\": 1\n",
    "                },\n",
    "                \"i32\": {\n",
    "                    \"ops_per_core_per_cycle\": 16,\n",
    "                    \"efficiency\": 1\n",
    "                }\n",
    "            },\n",
    "            \"name\": \"linalg.fill\"\n",
    "        },\n",
    "        \"linalg.generic\": {\n",
    "            \"datatypes\": {\n",
    "                \"i8\": {\n",
    "                    \"ops_per_core_per_cycle\": 1,\n",
    "                    \"efficiency\": 1\n",
    "                },\n",
    "                \"bf16\": {\n",
    "                    \"ops_per_core_per_cycle\": 1,\n",
    "                    \"efficiency\": 1\n",
    "                },\n",
    "                \"i32\": {\n",
    "                    \"ops_per_core_per_cycle\": 1,\n",
    "                    \"efficiency\": 1\n",
    "                }\n",
    "            },\n",
    "            \"name\": \"linalg.generic\"\n",
    "        },\n",
    "        \"linalg.matmul\": {\n",
    "            \"datatypes\": {\n",
    "                \"i8\": {\n",
    "                    \"macs_per_core_per_cycle\": 256,\n",
    "                    \"efficiency\": 1\n",
    "                },\n",
    "                \"bf16\": {\n",
    "                    \"macs_per_core_per_cycle\": 128,\n",
    "                    \"efficiency\": 1\n",
    "                },\n",
    "                \"i32\": {\n",
    "                    \"macs_per_core_per_cycle\": 32,\n",
    "                    \"efficiency\": 1\n",
    "                }\n",
    "            },\n",
    "            \"name\": \"linalg.matmul\"\n",
    "        }\n",
    "    },\n",
    "    \"dus\": {\n",
    "        \"count\": [4, 4],\n",
    "        \"memory\": {\n",
    "            \"memory_space\": \"L2\",\n",
    "            \"bytes\": 524288\n",
    "        },\n",
    "        \"ports\": {\n",
    "            \"outbound\": {\n",
    "                \"count\": 6,\n",
    "                \"bytes_per_second\": 4000000000\n",
    "            },\n",
    "            \"inbound\": {\n",
    "                \"count\": 6,\n",
    "                \"bytes_per_second\": 4000000000\n",
    "            }\n",
    "        },\n",
    "        \"tiles\": {\n",
    "            \"count\": [1, 4],\n",
    "            \"memory\": {\n",
    "                \"memory_space\": \"L1\",\n",
    "                \"bytes\": 65536\n",
    "            },\n",
    "            \"ports\": {\n",
    "                \"outbound\": {\n",
    "                    \"count\": 2,\n",
    "                    \"bytes_per_second\": 4000000000\n",
    "                },\n",
    "                \"inbound\": {\n",
    "                    \"count\": 2,\n",
    "                    \"bytes_per_second\": 4000000000\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"noc\": {\n",
    "        \"outbound\": {\n",
    "            \"count\": 4,\n",
    "            \"bytes_per_second\": 4000000000\n",
    "        },\n",
    "        \"inbound\": {\n",
    "            \"count\": 4,\n",
    "            \"bytes_per_second\": 4000000000\n",
    "        }\n",
    "    }\n",
    "  }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c94f7b77",
   "metadata": {},
   "source": [
    "Here are some utility functions to print out some performance stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018cece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import math\n",
    "import numpy\n",
    "\n",
    "def printMemoryFootprint(arch, trace_file_name):\n",
    "\n",
    "    # look up byte size per data type\n",
    "    datatype = arch[\"datatypes\"]\n",
    "\n",
    "    # trace model\n",
    "    with open(trace_file_name) as f:\n",
    "        trace_model = json.load(f)\n",
    "\n",
    "    # init dict\n",
    "    trace_dict = {}\n",
    "    for d in trace_model:\n",
    "        if d and d[\"name\"] == \"process_name\":\n",
    "            trace_dict[d[\"pid\"]] = [d[\"args\"][\"name\"], 0, 0]\n",
    "            name_split = re.split(r'\\[|\\]|, ', d[\"args\"][\"name\"])\n",
    "            trace_dict[d[\"pid\"]].append([eval(i) for i in name_split[1:-1]])\n",
    "\n",
    "    # go through traces\n",
    "    for d in trace_model:\n",
    "        if d and \"AllocOp\" in d[\"name\"] and d[\"ph\"] == \"B\":\n",
    "            name_split = re.split(r'\\(|\\)|, ', d[\"name\"])\n",
    "            vol = int(name_split[2])\n",
    "            ty = name_split[3]\n",
    "            datatype_size = [item[\"bytes\"] for item in datatype if item[\"name\"] == ty][0]\n",
    "            size = vol * datatype_size\n",
    "            trace_dict[d[\"pid\"]][1] = trace_dict[d[\"pid\"]][1] + size\n",
    "            trace_dict[d[\"pid\"]][2] = max(trace_dict[d[\"pid\"]][1], trace_dict[d[\"pid\"]][2])\n",
    "        if d and \"DeallocOp\" in d[\"name\"] and d[\"ph\"] == \"B\":\n",
    "            name_split = re.split(r'\\(|\\)|, ', d[\"name\"])\n",
    "            vol = int(name_split[2])\n",
    "            ty = name_split[3]\n",
    "            datatype_size = [item[\"bytes\"] for item in datatype if item[\"name\"] == ty][0]\n",
    "            size = vol * datatype_size\n",
    "            trace_dict[d[\"pid\"]][1] = trace_dict[d[\"pid\"]][1] - size\n",
    "\n",
    "    # get device capacity from device model\n",
    "    L1_memory_size = arch[\"dus\"][\"tiles\"][\"memory\"][\"bytes\"]\n",
    "    L2_memory_size = arch[\"dus\"][\"memory\"][\"bytes\"]\n",
    "    du_shape = arch[\"dus\"][\"tiles\"][\"count\"]\n",
    "\n",
    "    # performance stats\n",
    "    for i in range(1, len(trace_dict) + 1):\n",
    "        if \"air.herd\" in trace_dict[i][0]:\n",
    "            proc_name = trace_dict[i][0]\n",
    "            mem_usage = trace_dict[i][2]\n",
    "            print(proc_name + \" \" + str(i) + \" L1 memory peak util.: %\" + str(float(mem_usage) / float(L1_memory_size) * 100))\n",
    "        if \"air.segment\" in trace_dict[i][0]:\n",
    "            proc_name = trace_dict[i][0]\n",
    "            mem_usage = trace_dict[i][2]\n",
    "            du_usage = numpy.prod([math.ceil(j / k) for j, k in zip(trace_dict[i][3], du_shape)])\n",
    "            print(proc_name + \" \" + str(i) + \" L2 memory peak util.: %\" + str(float(mem_usage) / float(L2_memory_size * du_usage) * 100))\n",
    "        \n",
    "\n",
    "def printHerdComputeEfficiency(arch, trace_file_name):\n",
    "\n",
    "    # trace model\n",
    "    with open(trace_file_name) as f:\n",
    "        trace_model = json.load(f)\n",
    "\n",
    "    # init dict\n",
    "    trace_dict = {}\n",
    "    for d in trace_model:\n",
    "        if d and d[\"name\"] == \"process_name\" and \"air.herd\" in d[\"args\"][\"name\"]:\n",
    "            trace_dict[d[\"pid\"]] = [d[\"args\"][\"name\"], 0, 0]\n",
    "\n",
    "    # go through traces\n",
    "    for d in trace_model:\n",
    "        if d and \"LinalgOp\" in d[\"name\"] and d[\"ph\"] == \"B\":\n",
    "            trace_dict[d[\"pid\"]][1] = float(d[\"ts\"])\n",
    "        if d and \"LinalgOp\" in d[\"name\"] and d[\"ph\"] == \"E\":\n",
    "            compute_latency = float(d[\"ts\"]) - trace_dict[d[\"pid\"]][1]\n",
    "            trace_dict[d[\"pid\"]][2] = trace_dict[d[\"pid\"]][2] + compute_latency\n",
    "            trace_dict[d[\"pid\"]][1] = 0\n",
    "        if d and \"LaunchTerminator\" in d[\"name\"] and d[\"ph\"] == \"E\":\n",
    "            end_time = float(d[\"ts\"])\n",
    "    \n",
    "    # performance stats\n",
    "    for key, value in trace_dict.items():\n",
    "        if \"air.herd\" in value[0]:\n",
    "            proc_name = value[0]\n",
    "            print(proc_name + \" \" + str(key) + \" herd compute efficiency: %\" + str(float(value[2]) / float(end_time) * 100))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32598fe6",
   "metadata": {},
   "source": [
    "AIR-Runner expects two inputs: an MLIR-AIR program file and a JSON resource model which describes the target device. It generates a JSON time trace file formatted for Chrome tracing or Perfetto trace viewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "altered-hostel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency: 1895.697us\n",
      "air.segment[2, 2] 2 L2 memory peak util.: %3.90625\n",
      "air.herd[2, 2] 3 L1 memory peak util.: %9.375\n",
      "air.herd[2, 2] 3 herd compute efficiency: %10.371283159325136\n"
     ]
    }
   ],
   "source": [
    "# arch: resource model. \"trace.out\": output file name. \"herd\": simulation granularity (per herd or per core).\n",
    "runner = air.compiler.util.Runner(arch, \"trace.out\", \"herd\")\n",
    "# air_module: compiled MLIR-AIR program. \"matmul\": function name for simulation\n",
    "trace = runner.run(air_module, \"matmul\")\n",
    "\n",
    "# performance evaluation\n",
    "printMemoryFootprint(arch, \"trace.out\")\n",
    "printHerdComputeEfficiency(arch, \"trace.out\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b97b4654",
   "metadata": {},
   "source": [
    "After it finishes, a trace file named \"trace.out\" is generated. This trace file can be visualized using Perfetto: https://ui.perfetto.dev/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "854d8bd7",
   "metadata": {},
   "source": [
    "### Based on the simulation time traces, iteratively apply MLIR-AIR compiler optimizations to improve the program's performance on AIEs.\n",
    "\n",
    "- Optimization 1: data broadcasting, for loop data movement hoisting.\n",
    "\n",
    "Firstly, we can leverage AIE device's data broadcasting flexibility by broadcast copying pixels to multiple AIE tiles in parallel. Secondly, the partial pixels do not need to be copied in and out of the tile memory for every iteration of the for loop--it can persist in the tile memory.\n",
    "\n",
    "The `-air-dependency-schedule-opt` compilation pass can automatically detect such opportunities and perform optimizations. The `-air-specialize-dma-broadcast` specializes the code to explicitly represent the broadcast patterns for downstream compiler passes to map to hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8f964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency: 1641.377us\n",
      "air.segment[2, 2] 2 L2 memory peak util.: %3.90625\n",
      "air.herd[2, 2] 3 L1 memory peak util.: %9.375\n",
      "air.herd[2, 2] 3 herd compute efficiency: %11.978242645195165\n"
     ]
    }
   ],
   "source": [
    "with air.mlir.ir.Context(), Location.unknown():\n",
    "\n",
    "    air_module = matmul_on_tensors(256, 256, 1536, BF16Type.get())\n",
    "    \n",
    "    # convert linalg on tensors to linalg on memrefs\n",
    "    pm = air.mlir.passmanager.PassManager.parse(air.compiler.util.LINALG_TENSOR_TO_MEMREF_PIPELINE)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # tile and map to air\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        \"air-linalg-codegen{l2-tile-size=64,64,128 l2-promote=true l1-tile-size=32,32,32 l1-promote=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-par-to-herd{depth=1}\",\n",
    "        \"air-copy-to-dma\",\n",
    "        \"air-par-to-launch{has-air-segment=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # generate dependency information for runner\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        \"air-dependency\",\n",
    "        \"air-dependency-schedule-opt\", # <--------- new pass\n",
    "        \"air-specialize-dma-broadcast\", # <-------- new pass\n",
    "        \"air-dma-to-channel\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-dependency-canonicalize\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-place-herds{num-rows=2 num-cols=2 row-anchor=0 col-anchor=0}\"\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "runner = air.compiler.util.Runner(arch, \"trace.out\", \"herd\")\n",
    "trace = runner.run(air_module, \"matmul\")\n",
    "\n",
    "printMemoryFootprint(arch, \"trace.out\")\n",
    "printHerdComputeEfficiency(arch, \"trace.out\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e890b6de",
   "metadata": {},
   "source": [
    "- Optimization 2: Ping-pong buffering (both L1 and L2).\n",
    "\n",
    "Automatically double the buffer allocation to enable compute to overlap with data movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8da5fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency: 897.521us\n",
      "air.segment[2, 2] 2 L2 memory peak util.: %7.03125\n",
      "air.herd[2, 2] 3 L1 memory peak util.: %15.625\n",
      "air.herd[2, 2] 3 herd compute efficiency: %21.905695694803498\n"
     ]
    }
   ],
   "source": [
    "with air.mlir.ir.Context(), Location.unknown():\n",
    "\n",
    "    air_module = matmul_on_tensors(256, 256, 1536, BF16Type.get())\n",
    "    \n",
    "    # convert linalg on tensors to linalg on memrefs\n",
    "    pm = air.mlir.passmanager.PassManager.parse(air.compiler.util.LINALG_TENSOR_TO_MEMREF_PIPELINE)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # tile and map to air\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        \"air-linalg-codegen{l2-tile-size=64,64,128 l2-promote=true l1-tile-size=32,32,32 l1-promote=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-par-to-herd{depth=1}\",\n",
    "        \"air-copy-to-dma\",\n",
    "        \"air-par-to-launch{has-air-segment=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # generate dependency information for runner\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        \"air-dependency\",\n",
    "        \"air-dependency-schedule-opt\",\n",
    "        \"air-specialize-dma-broadcast\",\n",
    "        \"air-dma-to-channel\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-dependency-canonicalize\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-place-herds{num-rows=2 num-cols=2 row-anchor=0 col-anchor=0}\",\n",
    "        \"air-label-scf-for-to-ping-pong\", # <------ new pass\n",
    "        \"air-ping-pong-transform\" # <-------------- new pass\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "runner = air.compiler.util.Runner(arch, \"trace.out\", \"herd\")\n",
    "trace = runner.run(air_module, \"matmul\")\n",
    "\n",
    "printMemoryFootprint(arch, \"trace.out\")\n",
    "printHerdComputeEfficiency(arch, \"trace.out\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2af9fb6",
   "metadata": {},
   "source": [
    "- Optimization 3: Use up all available memory resources.\n",
    "\n",
    "Allocate all available L1 and L2 memory to the program. Finetune the tiling factors to balance between compute and communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3574e7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency: 528.485us\n",
      "air.segment[2, 2] 2 L2 memory peak util.: %40.625\n",
      "air.herd[2, 2] 3 L1 memory peak util.: %87.5\n",
      "air.herd[2, 2] 3 herd compute efficiency: %37.20226156326396\n"
     ]
    }
   ],
   "source": [
    "with air.mlir.ir.Context(), Location.unknown():\n",
    "\n",
    "    air_module = matmul_on_tensors(256, 256, 1536, BF16Type.get())\n",
    "    \n",
    "    # convert linalg on tensors to linalg on memrefs\n",
    "    pm = air.mlir.passmanager.PassManager.parse(air.compiler.util.LINALG_TENSOR_TO_MEMREF_PIPELINE)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # tile and map to air\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        \"air-linalg-codegen{l2-tile-size=128,128,384 l2-promote=true l1-tile-size=64,64,96 l1-promote=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-par-to-herd{depth=1}\",\n",
    "        \"air-copy-to-dma\",\n",
    "        \"air-par-to-launch{has-air-segment=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # generate dependency information for runner\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        \"air-dependency\",\n",
    "        \"air-dependency-schedule-opt\",\n",
    "        \"air-specialize-dma-broadcast\",\n",
    "        \"air-dma-to-channel\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-dependency-canonicalize\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-place-herds{num-rows=2 num-cols=2 row-anchor=0 col-anchor=0}\",\n",
    "        \"air-label-scf-for-to-ping-pong\",\n",
    "        \"air-ping-pong-transform\"\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "runner = air.compiler.util.Runner(arch, \"trace.out\", \"herd\")\n",
    "trace = runner.run(air_module, \"matmul\")\n",
    "\n",
    "printMemoryFootprint(arch, \"trace.out\")\n",
    "printHerdComputeEfficiency(arch, \"trace.out\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11df6c33",
   "metadata": {},
   "source": [
    "- Optimization 4: Double mem tile port usage.\n",
    "\n",
    "The target device has unused ports for data movement between L1 and L2. Allocate more ports to increase the bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50da7900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency: 418.125us\n",
      "air.segment[2, 2] 2 L2 memory peak util.: %40.625\n",
      "air.herd[2, 2] 3 L1 memory peak util.: %87.5\n",
      "air.herd[2, 2] 3 herd compute efficiency: %47.02145774937579\n"
     ]
    }
   ],
   "source": [
    "with air.mlir.ir.Context(), Location.unknown():\n",
    "\n",
    "    air_module = matmul_on_tensors(256, 256, 1536, BF16Type.get())\n",
    "    \n",
    "    # convert linalg on tensors to linalg on memrefs\n",
    "    pm = air.mlir.passmanager.PassManager.parse(air.compiler.util.LINALG_TENSOR_TO_MEMREF_PIPELINE)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # tile and map to air\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        \"air-linalg-codegen{l2-tile-size=128,128,384 l2-promote=true l1-tile-size=64,64,96 l1-promote=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-par-to-herd{depth=1}\",\n",
    "        \"air-copy-to-dma\",\n",
    "        \"air-par-to-launch{has-air-segment=true}\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "    # generate dependency information for runner\n",
    "    pipeline = \"builtin.module(\"+\",\".join([\n",
    "        \"air-dependency\",\n",
    "        \"air-dependency-schedule-opt\",\n",
    "        \"air-specialize-dma-broadcast\",\n",
    "        \"air-dma-to-channel\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-dependency-canonicalize\",\n",
    "        \"canonicalize\", \"cse\",\n",
    "        \"air-place-herds{num-rows=2 num-cols=2 row-anchor=0 col-anchor=0}\",\n",
    "        \"air-unroll-channel-by-factor{channel-name=channel_5 unroll-dim=0 unroll-factor=2}\",\n",
    "        \"air-unroll-channel-by-factor{channel-name=channel_6 unroll-dim=0 unroll-factor=2}\",\n",
    "        \"air-label-scf-for-to-ping-pong\",\n",
    "        \"air-ping-pong-transform\"\n",
    "    ])+')'\n",
    "    pm = air.mlir.passmanager.PassManager.parse(pipeline)\n",
    "    pm.run(air_module.operation)\n",
    "\n",
    "runner = air.compiler.util.Runner(arch, \"trace.out\", \"herd\")\n",
    "trace = runner.run(air_module, \"matmul\")\n",
    "\n",
    "printMemoryFootprint(arch, \"trace.out\")\n",
    "printHerdComputeEfficiency(arch, \"trace.out\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f02dfbd",
   "metadata": {},
   "source": [
    "Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
